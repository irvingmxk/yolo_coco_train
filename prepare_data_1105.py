#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‡†å¤‡ data_1029 æ•°æ®é›†
å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¹¶ç”Ÿæˆé…ç½®æ–‡ä»¶
"""

import os
import shutil
from pathlib import Path
import random
import yaml

def split_dataset(data_dir, val_split=0.2, seed=42):
    """
    å°†æ•°æ®é›†åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
    """
    data_dir = Path(data_dir)
    images_dir = data_dir / 'images'
    labels_dir = data_dir / 'labels'
    
    print("=" * 60)
    print("å‡†å¤‡æ•°æ®é›†: data_1105")
    print("=" * 60)
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))
    image_files = sorted(image_files)
    
    print(f"\nâœ… æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    
    # éšæœºæ‰“ä¹±
    random.seed(seed)
    random.shuffle(image_files)
    
    # åˆ†å‰²
    val_size = int(len(image_files) * val_split)
    train_files = image_files[val_size:]
    val_files = image_files[:val_size]
    
    print(f"ğŸ“Š æ•°æ®åˆ’åˆ†:")
    print(f"   è®­ç»ƒé›†: {len(train_files)} å¼  ({(1-val_split)*100:.0f}%)")
    print(f"   éªŒè¯é›†: {len(val_files)} å¼  ({val_split*100:.0f}%)")
    
    # åˆ›å»ºç›®å½•ç»“æ„
    for split in ['train', 'val']:
        (data_dir / split / 'images').mkdir(parents=True, exist_ok=True)
        (data_dir / split / 'labels').mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•
    def copy_files(file_list, split_name):
        copied = 0
        for img_path in file_list:
            label_path = labels_dir / (img_path.stem + '.txt')
            
            # å¤åˆ¶å›¾ç‰‡
            dst_img = data_dir / split_name / 'images' / img_path.name
            shutil.copy(img_path, dst_img)
            
            # å¤åˆ¶æ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if label_path.exists():
                dst_label = data_dir / split_name / 'labels' / label_path.name
                shutil.copy(label_path, dst_label)
                copied += 1
        return copied
    
    print(f"\nğŸ“ æ­£åœ¨å¤åˆ¶æ–‡ä»¶...")
    train_copied = copy_files(train_files, 'train')
    val_copied = copy_files(val_files, 'val')
    
    print(f"   è®­ç»ƒé›†: {train_copied}/{len(train_files)} ä¸ªæ ‡ç­¾æ–‡ä»¶")
    print(f"   éªŒè¯é›†: {val_copied}/{len(val_files)} ä¸ªæ ‡ç­¾æ–‡ä»¶")
    
    if train_copied < len(train_files) or val_copied < len(val_files):
        print(f"\nâš ï¸  éƒ¨åˆ†å›¾ç‰‡æ²¡æœ‰å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶")
    
    print(f"\nâœ… æ•°æ®é›†åˆ†å‰²å®Œæˆï¼")
    return len(train_files), len(val_files)

def create_data_yaml(data_dir):
    """
    åˆ›å»ºYOLOæ•°æ®é…ç½®æ–‡ä»¶
    """
    data_dir = Path(data_dir).absolute()
    classes_file = data_dir / 'classes.txt'
    
    # è¯»å–ç±»åˆ«
    with open(classes_file, 'r', encoding='utf-8') as f:
        class_names = [line.strip() for line in f if line.strip()]
    
    print(f"\nğŸ“‹ æ£€æµ‹ç±»åˆ«:")
    for i, name in enumerate(class_names):
        print(f"   {i}: {name}")
    
    # åˆ›å»ºé…ç½®
    data_config = {
        'path': str(data_dir),
        'train': 'train/images',
        'val': 'val/images',
        'nc': len(class_names),
        'names': class_names
    }
    
    yaml_path = data_dir / 'data.yaml'
    with open(yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(data_config, f, allow_unicode=True, sort_keys=False)
    
    print(f"\nâœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º: {yaml_path}")
    return yaml_path

def check_data_quality(data_dir):
    """
    æ£€æŸ¥æ•°æ®è´¨é‡
    """
    data_dir = Path(data_dir)
    
    print(f"\n" + "=" * 60)
    print("æ•°æ®è´¨é‡æ£€æŸ¥")
    print("=" * 60)
    
    for split in ['train', 'val']:
        images_dir = data_dir / split / 'images'
        labels_dir = data_dir / split / 'labels'
        
        images = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))
        labels = list(labels_dir.glob('*.txt'))
        
        print(f"\n{split.upper()}:")
        print(f"  å›¾ç‰‡æ•°é‡: {len(images)}")
        print(f"  æ ‡ç­¾æ•°é‡: {len(labels)}")
        
        if len(images) != len(labels):
            print(f"  âš ï¸  å›¾ç‰‡å’Œæ ‡ç­¾æ•°é‡ä¸åŒ¹é…")
        else:
            print(f"  âœ… å›¾ç‰‡å’Œæ ‡ç­¾æ•°é‡åŒ¹é…")
        
        # æ£€æŸ¥ç©ºæ ‡ç­¾
        empty_labels = 0
        for label_file in labels:
            if label_file.stat().st_size == 0:
                empty_labels += 1
        
        if empty_labels > 0:
            print(f"  âš ï¸  æœ‰ {empty_labels} ä¸ªç©ºæ ‡ç­¾æ–‡ä»¶")
        else:
            print(f"  âœ… æ— ç©ºæ ‡ç­¾æ–‡ä»¶")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("\n")
    print("â•”" + "=" * 58 + "â•—")
    print("â•‘" + " " * 15 + "å‡†å¤‡ data_1105 æ•°æ®é›†" + " " * 15 + "â•‘")
    print("â•š" + "=" * 58 + "â•")
    print()
    
    # æ•°æ®ç›®å½•
    data_dir = Path('/workspace/yolo/data_1105')
    
    if not data_dir.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»åˆ†å‰²
    if (data_dir / 'train').exists() and (data_dir / 'val').exists():
        print("âš ï¸  æ•°æ®é›†å·²ç»åˆ†å‰²è¿‡äº†")
        response = input("æ˜¯å¦é‡æ–°åˆ†å‰²? (y/n): ").lower()
        if response != 'y':
            print("è·³è¿‡æ•°æ®åˆ†å‰²")
        else:
            # åˆ é™¤æ—§çš„åˆ†å‰²
            print("æ­£åœ¨åˆ é™¤æ—§çš„åˆ†å‰²...")
            shutil.rmtree(data_dir / 'train', ignore_errors=True)
            shutil.rmtree(data_dir / 'val', ignore_errors=True)
            
            # é‡æ–°åˆ†å‰²
            split_dataset(data_dir, val_split=0.2)
    else:
        # åˆ†å‰²æ•°æ®é›†
        split_dataset(data_dir, val_split=0.2)
    
    # åˆ›å»ºé…ç½®æ–‡ä»¶
    yaml_path = create_data_yaml(data_dir)
    
    # æ£€æŸ¥æ•°æ®è´¨é‡
    check_data_quality(data_dir)
    
    print("\n" + "=" * 60)
    print("æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“‚ æ•°æ®ç›®å½•: {data_dir}")
    print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {yaml_path}")
    print(f"\nğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†:")
    print(f"   python train_yolo11n.py")
    print()

if __name__ == '__main__':
    main()